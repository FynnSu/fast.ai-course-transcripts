WEBVTT

00:00.000 --> 00:07.880
 Beginning of our end of last class, I introduced just kind of the start of

00:12.000 --> 00:18.600
 the start of lesson four on compressed sensing of CT scans. And I just wanted, we

00:18.600 --> 00:22.720
 talked about a few really useful concepts at the beginning and I wanted

00:22.720 --> 00:27.580
 to review those. And so one of those was broadcasting and NumPy and that's how

00:27.580 --> 00:32.560
 NumPy deals with arrays of different shapes and kind of the rules for whether

00:32.560 --> 00:38.400
 or not you can do arithmetic on them. Can anyone remind us what the kind of two

00:38.400 --> 00:44.200
 rules for broadcasting are in NumPy?

00:44.200 --> 01:09.240
 Connor? Yes, exactly. And then for lining them up, do you start at the kind of

01:09.240 --> 01:22.380
 beginning or end? Wait, Jeremy, throw it back. Yes, exactly. Yeah, thank you. Yeah,

01:22.380 --> 01:27.920
 those are the rules for broadcasting. Start with the trailing

01:27.920 --> 01:32.200
 dimensions, which is the far right-hand side, and then two dimensions are

01:32.200 --> 01:37.280
 compatible if they're either equal or one of them is one. And so then I wrote a

01:37.280 --> 01:43.040
 few problems as review. So suppose we have, actually is the font large enough

01:43.040 --> 01:59.960
 on this? Is that better? Let me, okay, so we've got V, which is 3, so 3, just a

01:59.960 --> 02:09.360
 tuple. M is 3x3 and A is 2x3x3. And so kind of before we actually run these,

02:09.360 --> 02:15.720
 which of the following operations will work and which won't? So take a moment to

02:15.720 --> 02:30.960
 think about these and then you can do like a thumbs up, thumbs down, maybe.

02:47.080 --> 02:53.800
 Okay, does anyone want more time? Okay, so for the first one, A plus B. Thumbs up if

02:53.800 --> 03:02.160
 you think that'll work, thumbs down if you think that it won't work. Thanks for

03:02.160 --> 03:07.440
 everyone that's participating. Yeah, I see mostly thumbs up and that's

03:07.440 --> 03:13.640
 correct, that works. So, and yeah, V may be a little bit confusing since it's

03:13.640 --> 03:21.520
 kind of just got this single dimension showing up. But yeah, that works. The

03:21.520 --> 03:26.320
 threes line up and then we've got the two and three before. And so what's

03:26.320 --> 03:35.480
 happening with that is that, it actually might be helpful to put A here so you

03:35.480 --> 03:45.320
 can see one has been added kind of to this whole first column along both

03:45.320 --> 03:49.880
 matrices, if you think of this as being like an array of two matrices. And

03:49.880 --> 03:56.000
 then we've got two was added along this whole second column and three was added

03:56.000 --> 04:04.340
 here. Let's go on to the next one. How about A plus M? And I should leave the

04:04.340 --> 04:09.680
 dimensions up so you can see. Thumbs up if you think A plus M will work, thumbs

04:09.680 --> 04:17.180
 down if not. Excellent. So yeah, so all thumbs up and that works because the

04:17.180 --> 04:20.780
 three by three lines up with the three by three at the end of two by three by

04:20.780 --> 04:30.480
 three. So we can do that. And there matrix M is kind of being added to, you know,

04:30.480 --> 04:35.280
 this first matrix in A and to the second matrix in A. And how about A dot

04:35.280 --> 04:44.200
 transpose, or A transpose plus M? Thumbs up or thumbs down? Great. Yeah, I see a lot

04:44.200 --> 04:50.040
 of thumbs down. And this is nice, we get the error, operands could not be

04:50.040 --> 04:54.440
 broadcast together with shapes three three two and three three. Now you

04:54.440 --> 05:00.120
 understand what that error means if you get it. Any questions about broadcasting?

05:00.120 --> 05:04.120
 Kelsey?

05:04.120 --> 05:22.240
 So that, and actually it's probably helpful for me to to show it. So that's

05:22.240 --> 05:37.000
 reversing the, let me also put, let me change this to A so you can have kind of

05:37.000 --> 05:46.400
 like the visualization. So here we're taking 5, 10, 15. So basically we end up

05:46.400 --> 05:50.520
 taking kind of the the first column of this matrix and the first column of this

05:50.520 --> 05:56.840
 one and putting those together to get this new first matrix. And then kind of

05:56.840 --> 06:01.320
 second column here, 10, 20, 30, and negative 2, negative 4, negative 6, and

06:01.320 --> 06:07.720
 putting those together. And then 15, 30, 45, negative 3, negative 6, negative 9, and

06:07.720 --> 06:13.280
 putting those together. Let me do this again. I think it'll be clearer since

06:13.280 --> 06:17.160
 we've got three showing up as a dimension twice. Let me do something with

06:17.160 --> 06:21.160
 completely different dimensions.

06:26.600 --> 06:35.040
 So you're, I think you're reversing the order of the dimensions. Yeah. Okay, but

06:35.040 --> 06:43.080
 now I've got A234, so I think this will be kind of a nice example. So when we

06:43.080 --> 06:49.280
 reverse the, completely reverse the order of dimensions it becomes 432. And then

06:49.280 --> 06:56.440
 this is what A transpose looks like. And I definitely also recommend kind of

06:56.440 --> 06:59.400
 looking at small test cases of these because I think often it's helpful to

06:59.400 --> 07:04.800
 kind of visualize how they're changing. Yeah, good question. Any other questions

07:04.800 --> 07:15.280
 about broadcasting? Okay, so next up we talked about how SciPy stores sparse

07:15.280 --> 07:26.920
 matrices and that there were a few different matrix storage formats. Let's

07:26.920 --> 07:42.360
 see, can anyone describe how, how coordinate-wise storage works? Matthew?

07:47.720 --> 07:52.200
 Exactly, yeah. So you're keeping track of the index for the row, the index for the

07:52.200 --> 07:57.720
 column, and the value that you want there. Great. And what's a, what's an advantage

07:57.720 --> 08:15.320
 of this, this approach? Actually, advantage or disadvantage? So less memory than a

08:15.320 --> 08:27.120
 dense matrix. Yes, yes. Right, so it's harder to get an entire row or an entire

08:27.120 --> 08:34.040
 column. Exactly, yes, yes. So if you wanted to find everything in a particular row

08:34.040 --> 08:39.840
 you would have to go through your array of row indices and pick out those kind

08:39.840 --> 08:45.840
 of corresponding values. Alright, and so then kind of this was an example we saw

08:45.840 --> 08:51.120
 last time of, and they've used this nice color coding to show like 75 is in row

08:51.120 --> 08:57.560
 six, column four. Over here we have value 75, row six, column four, and that's how

08:57.560 --> 09:06.560
 it's being stored. Next step is, oh and then this is also kind of illustrating

09:06.560 --> 09:11.400
 for things like matrix multiplication, you can just, you know, look up what you

09:11.400 --> 09:15.400
 have in your value array. You're not having to go through all the spaces where

09:15.400 --> 09:24.120
 you have zeros. Alright, so compressed sparse row data structure. Can anyone

09:24.120 --> 09:46.160
 describe what's going on with that picture? Sam?

09:46.160 --> 10:04.560
 So to save space, the row indices are not repeated. It just says which of the n observations is the first that has that row in the order by rows?

10:04.560 --> 10:10.360
 Exactly, yes. So this uses even less space than the coordinate sparse storage

10:10.360 --> 10:14.440
 because it just keeps track of a row pointer, which as Sam said, it's just kind

10:14.440 --> 10:19.200
 of telling you the first place that, or the first value that that's on that row.

10:19.200 --> 10:26.000
 So for row one, the third value is the first to show up there, which is 22. And

10:26.000 --> 10:31.800
 so we see that's the first value on row one. And for, let's see what else they

10:31.800 --> 10:41.060
 color-coded, row three, the ninth value is the first there. And so you can see the

10:41.060 --> 10:48.920
 ninth value is 42, and that's the first thing on row three. So what are

10:48.920 --> 10:55.600
 some benefits and or pros and cons of this approach?

10:55.600 --> 11:19.600
 I think when we are trying to look for non-zero elements of that matrix, you don't have to go through all the non-zero elements, you can just skip row by row until you get to the row which you need.

11:19.600 --> 11:29.600
 So if you're looking up a particular row, yes, it's very quick to do that. Yeah, fast lookup by rows. And then can you think of a disadvantage?

11:29.600 --> 11:37.600
 By columns it will be just the same complexity of n in the worst case.

11:37.600 --> 11:47.600
 Yeah, so column lookup is painful, or yeah, more painful because you're kind of having to go backwards to calculate. Thank you.

11:47.600 --> 12:03.880
 Wait, throw the microphone. It's for the video. So the row pointer, great question, is telling you, so there the index is

12:03.880 --> 12:11.720
 telling you kind of where that row starts. So row zero, the first one is in

12:11.720 --> 12:17.060
 value zero. So how index is being used is different for value and row

12:17.060 --> 12:23.060
 pointer. Actually it's probably easier to look at. So the first three

12:23.060 --> 12:27.720
 values are in row zero. So you really just need to store a zero and then this

12:27.720 --> 12:35.800
 three lets you know, okay, now we've moved on to row one. And the kind of starting

12:35.800 --> 12:41.040
 with index zero, the third value 22, so if you go over here, the third value is 22,

12:41.040 --> 12:48.240
 that's the first thing in row one. And then we've got three values here and

12:48.240 --> 12:52.360
 then value six is the first thing in row two. So down here we store six for the

12:52.360 --> 13:04.200
 row pointer. So it's that saying row two starts with value six, which is 31. So the

13:04.200 --> 13:10.560
 for the row pointer, yeah, the index is telling you the row number. And it's

13:10.560 --> 13:17.440
 telling you that, though, in terms of what the index for the value is. Tim's got his

13:17.440 --> 13:19.880
 hand up.

13:19.880 --> 13:41.080
 Yeah, that's a great way of putting it. Like you can kind of think about like

13:41.080 --> 13:46.320
 you've turned, you've turned this matrix into an array of values 11, 12, 14, 22, 23,

13:46.320 --> 13:52.320
 25, 31. And you, yeah, you want to keep track of where you're switching from one

13:52.320 --> 13:57.680
 row to another. And so you're just kind of keeping track of, okay, we switch, or

13:57.680 --> 14:02.720
 you know, we started a row here at 11, then another row started at 22, another

14:02.720 --> 14:08.620
 row started at 31, another row started at 42, and so we just need a pointer to

14:08.620 --> 14:29.520
 those spots where a new row is starting. Okay, let me go to, you will like this

14:29.520 --> 14:48.320
 table better, Terrence. So this table, okay, you're welcome. Any other questions

14:48.320 --> 14:55.400
 about compressed storage or sparse arrays? And so we didn't go into detail

14:55.400 --> 15:02.120
 on the compressed column storage, but it's the exact same idea as compressed

15:02.120 --> 15:09.200
 row, only you're keeping track of column pointers. And it's fast to look up a

15:09.200 --> 15:26.320
 particular column, but in that case it's slow to look up a row. Kelsey? That's a

15:26.320 --> 15:35.320
 good question. I would have to look that up. Let me write that down. Something

15:35.320 --> 15:41.320
 also to remember is that converting between these types is linear time, so I

15:41.320 --> 15:47.600
 think generally they kind of recommend converting if you're going to, yeah, be

15:47.600 --> 15:50.920
 looking up a lot of rows or looking up a lot of columns. But yeah, I'll tell you the

15:50.920 --> 15:54.320
 exact times next time.

15:54.320 --> 16:04.920
 Any other questions?

16:09.480 --> 16:15.240
 I have this question. So like, once we know that we have sparse matrix and we

16:15.240 --> 16:21.720
 try to decide which format to use, so like can we just look up for every

16:21.720 --> 16:26.600
 format, like this format is better for matrix multiplication, this form is

16:26.600 --> 16:31.680
 better for like trying to get the inverse, this form is better for like to

16:31.680 --> 16:36.320
 get the transpose matrix, or maybe this form is better for multiplying matrix by

16:36.320 --> 16:43.080
 columns or stuff like that. Yeah, so yeah, different operations, and I don't know if

16:43.080 --> 16:48.080
 it, I think some of the things you listed will probably be equally good in both,

16:48.080 --> 16:52.400
 but yeah, it's very dependent on what algorithm you're using. And so

16:52.400 --> 16:56.680
 particularly like looking at your code as well of if, kind of if you're

16:56.680 --> 17:02.320
 accessing things by row or by column in a loop, that should be a factor. And I've

17:02.320 --> 17:09.260
 copied a little bit of, yeah, so here like the SciPy documentation says that for

17:09.260 --> 17:13.800
 multiplication or inversion it recommends either CSC or CSR, so I

17:13.800 --> 17:17.840
 think that those are probably equally good. Yeah, if you're doing something

17:17.840 --> 17:21.560
 else where you are, you know, looping through your rows or looping through

17:21.560 --> 17:27.600
 your columns, you'd want to think about that. You're welcome, good question. And

17:27.600 --> 17:34.000
 then it also says COO I think is a good format for constructing your

17:34.000 --> 17:38.080
 matrices since you don't want to have to be calculating the row or column

17:38.080 --> 17:42.880
 pointers yourself typically, and it's efficient to convert then, so kind of

17:42.880 --> 17:49.600
 use COO to make your, pass your matrix into SciPy.

17:58.040 --> 18:04.120
 Okay, yeah, so we'll be using both broadcasting and sparse

18:04.120 --> 18:10.800
 storage today. I'm going back to this problem of CT scans, and so I showed last

18:10.800 --> 18:18.040
 time in this article that I think is very nicely written. It starts with can

18:18.040 --> 18:23.720
 math really save your life? Of course it can, and talking about kind of how CT

18:23.720 --> 18:34.120
 scans work. I want to try introducing this in a different way today. So if

18:34.120 --> 18:39.680
 you were actually kind of working on CT scan data, what would happen is you would

18:39.680 --> 18:43.840
 be receiving some data that might like look like this on the left-hand side, and

18:43.840 --> 18:49.600
 you're trying to reconstruct this full picture. And the idea, and so this is in

18:49.600 --> 18:55.560
 real life this is usually 3D, we're just gonna be looking at a 2D picture. And

18:55.560 --> 19:02.680
 here are the dimensions of this. This is L width for both of them, but then this

19:02.680 --> 19:10.120
 is just a seventh as tall, what you started with. And the idea is, you know, it

19:10.120 --> 19:14.480
 seems clear if you did a ton of x-rays of someone, you know, from every

19:14.480 --> 19:18.200
 angle and got all this data that you'd be able to reconstruct the original, but

19:18.200 --> 19:21.840
 you want to limit how much radiation people are experiencing. And so the idea

19:21.840 --> 19:27.200
 is that we're kind of getting, you know, like much much smaller amount of data

19:27.200 --> 19:32.160
 and want to reconstruct this picture that includes a larger amount of data. So

19:32.160 --> 19:35.200
 it's kind of like the opposite of data compression and that you're kind of

19:35.200 --> 19:40.480
 starting with the smaller amount of data and need to uncompress it to get the

19:40.480 --> 19:47.640
 full picture. And then it's also you're having to find kind of the meaning of

19:47.640 --> 19:51.520
 yeah kind of what these measurements, so these would be the measurements from

19:51.520 --> 19:56.960
 different x-rays shot at different angles and different locations and then

19:56.960 --> 20:03.020
 getting back to okay what would that mean for the picture. There are questions

20:03.020 --> 20:12.320
 about kind of the setup. And so this problem, since we're using, we're gonna

20:12.320 --> 20:15.800
 use data that we generate for the problem, like we're gonna be building

20:15.800 --> 20:20.920
 this picture, it's different from a kind of real CT scan in that we first will

20:20.920 --> 20:25.200
 have to make our data, then get what the measurements would be, and then we're

20:25.200 --> 20:31.520
 seeing if we can reconstruct the original just from these measurements.

20:36.040 --> 20:42.120
 Yeah, so I'm gonna show some pictures but I kind of what it'll look like

20:42.120 --> 20:47.760
 is that an x-ray shot at a particular angle and a particular location, you're

20:47.760 --> 20:50.800
 just gonna get a single number from that. So you know here we have a line

20:50.800 --> 20:55.560
 intersecting with our picture and that would result in just one number. So kind

20:55.560 --> 21:05.280
 of one pixel in this left-hand side of our measurements. And then this is a kind

21:05.280 --> 21:10.640
 of brief review. So from the background removal lesson, that was background

21:10.640 --> 21:19.200
 removal using robust PCA was written as this optimization problem. And do you

21:19.200 --> 21:30.600
 remember what's special about the L1 norm? Shout it out. Yeah, it shrinks things

21:30.600 --> 21:35.180
 to zero resulting in a sparse solution, right? So it induces sparsity because

21:35.180 --> 21:39.400
 yeah, it's kind of pushing many of the coefficients to zero. And so

21:39.400 --> 21:44.540
 you'll notice this picture that we'll be trying to construct is

21:44.540 --> 21:49.720
 sparse. So we'll be using the L1 norm today.

21:55.960 --> 22:00.800
 Okay, so the first part of this is just generating the data and I

22:00.800 --> 22:08.120
 think this uses some interesting NumPy methods that some of them I

22:08.120 --> 22:14.320
 hadn't even seen before. So I think it's an interesting process. Again, if you were

22:14.320 --> 22:23.920
 really working with CT scans, you're not building your own fake data set. And so

22:23.920 --> 22:28.840
 here we're choosing 128 for the dimension. So this is 128 by 128. And I'm

22:28.840 --> 22:36.400
 gonna kind of walk through what this code is doing. So this is the whole

22:36.400 --> 22:40.520
 method for generating synthetic data. This will return kind of

22:40.520 --> 22:51.880
 one square like this, but we'll walk through that more slowly. And to

22:51.880 --> 22:54.880
 walk through it, I'm gonna go through kind of a smaller example of just

22:54.880 --> 23:02.880
 creating an 8x8 picture that has five points. And we'll see what the

23:02.880 --> 23:10.480
 points mean in a moment, but that'll give you kind of the density of the data set.

23:10.480 --> 23:19.640
 Of those white circles. So there's a NumPy method called ogrid that

23:19.640 --> 23:26.600
 returns something as a column and as a row. And so here we're

23:26.600 --> 23:34.200
 getting the numbers 0 to 7 as a column and as a row back. And then this is

23:34.200 --> 23:36.520
 actually going to be very handy in a moment. We're gonna use

23:36.520 --> 23:41.880
 broadcasting with this. So we want to end up getting something that's 7 by 7 or

23:41.880 --> 23:46.960
 sorry 8 by 8. So we're kind of getting this row and column and we can do some

23:46.960 --> 23:50.800
 operations and together with broadcasting that's gonna go from you

23:50.800 --> 23:56.720
 know having something that is 8 by 1 and 1 by 8 to something that's 8 by 8.

23:56.720 --> 24:03.080
 It's kind of a handy trick. And so this is basically kind of like the

24:03.080 --> 24:09.040
 equation for a circle. We're saying X minus the center point squared plus Y

24:09.040 --> 24:14.800
 minus the center point squared. And we get and then kind of combining that with

24:14.800 --> 24:19.280
 broadcasting so the X part of the equation is still just going to be you

24:19.280 --> 24:25.000
 know this 8 by 1 column. The Y part is this 1 by 8 row. And when we add those

24:25.000 --> 24:32.800
 together we get an 8 by 8 grid. And this kind of has a density of being 0 at the

24:32.800 --> 24:36.080
 center and then getting larger as you go further away since we're using the

24:36.080 --> 25:03.880
 circular equation. Questions about this? Jeremy? Oh yes that's a great idea.

25:03.880 --> 25:08.200
 And here since 0 is the first entry of both you can kind of see the original X

25:08.200 --> 25:13.520
 in the first column and the original Y here.

25:13.520 --> 25:35.400
 Okay so now we're constructing something called mask outer and basically that's

25:35.400 --> 25:39.520
 because we're just going to be kind of interested in this center in the kind of

25:39.520 --> 25:44.480
 the center of our picture. And I think this is kind of fitting with the idea of

25:44.480 --> 25:49.640
 you know if you thought about doing a CT scan of someone's you know someone's

25:49.640 --> 25:53.880
 torso that you're kind of getting this like circular cross-section is what

25:53.880 --> 26:00.160
 we're getting here. So we're just adding an inequality so kind of taking you know

26:00.160 --> 26:07.360
 our XY grid and then seeing when it's less than this radius squared that gives

26:07.360 --> 26:14.080
 us this outer mask which is kind of us you know a ball of trues surrounded with

26:14.080 --> 26:22.000
 false at the border. And this is also important I should say I guess because

26:22.000 --> 26:25.600
 the the x-ray will be coming at different angles like this kind of

26:25.600 --> 26:32.880
 ensures that it's going through the same amount of you know person being x-rayed

26:32.880 --> 26:39.920
 kind of from each angle the x-rays traveling a similar distance. So we take

26:39.920 --> 26:45.960
 that mask oh that's our outer mask and then we're constructing something called

26:45.960 --> 26:51.320
 mask where we just randomly generate some points in a 2d grid. And so that was

26:51.320 --> 26:55.280
 a parameter earlier kind of how many points we wanted to generate and in this

26:55.280 --> 26:59.480
 case it's five so we've still got something eight by eight and it's all

26:59.480 --> 27:09.680
 zeros with five ones and we can plot what that looks like so here we're just

27:09.680 --> 27:19.960
 plotting kind of each each point is a pixel zero or one and we have five five

27:19.960 --> 27:28.500
 white boxes. We'll use a a Gaussian filter then to kind of blur that so

27:28.500 --> 27:33.280
 that's kind of going around these places but making it a bit more kind of

27:33.280 --> 27:35.840
 continuous.

27:40.920 --> 27:45.000
 And this is I mean some of this is uh you know this is specific to kind of

27:45.000 --> 27:51.160
 like we're trying to get these like globby looking shapes in our in our data.

27:51.160 --> 27:59.400
 Here we combine seeing when so now we've kind of gotten the Gaussian filter

27:59.400 --> 28:03.520
 version we're just gonna take the parts of that that are greater than the mean

28:03.520 --> 28:09.880
 for it and then also when when those points lie inside that inner circle. And

28:09.880 --> 28:13.920
 so that's what this is.

28:13.920 --> 28:27.720
 And then actually I should um maybe pull up ND image well I'll come back to that

28:27.720 --> 28:32.400
 in a moment we're kind of using this additional library here is where we get

28:32.400 --> 28:37.040
 this binary erosion feature from and this is just picking out the middle so

28:37.040 --> 28:40.400
 kind of this was our whole thing we want to separate that into what was the

28:40.400 --> 28:48.960
 middle and what was the exterior. And so this is how we make yeah kind of make

28:48.960 --> 28:52.440
 those globs that you saw and this is a more pixelated version since it's just

28:52.440 --> 28:56.600
 eight by eight whereas our original was much larger. But this actually let me

28:56.600 --> 29:04.120
 scroll back up so kind of this circular shape or not circular globby shape here

29:04.120 --> 29:16.160
 that's how we would get kind of the globby shapes here. Jeremy oh yes yeah

29:16.160 --> 29:27.520
 the caret sign is XOR which is exclusive or actually first let me just see where

29:27.520 --> 29:35.960
 ND image okay so that is a sci-fi library I'll go back to that yeah so

29:35.960 --> 29:45.000
 Jeremy pointed out the the binary erosion gives us the the inside really

29:45.000 --> 29:51.600
 what we want is what's left over and so we're taking an exclusive or with kind

29:51.600 --> 29:58.320
 of between this picture the result that's everything exclusive or with this

29:58.320 --> 30:27.600
 interior just leaves us with the exterior.

30:27.600 --> 30:30.880
 And then I just wanted to pull up because I think this is an interesting

30:30.880 --> 30:35.440
 library we're just using a little bit of functionality from it but sci-fi has an

30:35.440 --> 30:40.280
 ND image for multi-dimensional image processing kind of as a library so if

30:40.280 --> 30:46.480
 you're interested in it I think that would be something to check out with

30:46.480 --> 30:53.360
 yeah with different types of filters. Other questions kind of so far what

30:53.360 --> 31:00.800
 we're doing to create these globs?

31:05.040 --> 31:13.440
 Can I have a question about this Gaussian filter? Is this something like the EM model?

31:13.440 --> 31:21.280
 Remind me what the EM model is. So we assume that there are like a few Gaussian

31:21.280 --> 31:27.640
 distributions and then we assign probabilities to every pixel that was

31:27.640 --> 31:35.920
 derived like from white distribution or from black distribution by looking for the maximum likelihood.

31:35.920 --> 31:44.240
 I think this is more like putting a Gaussian centered at each point and kind of looking at what shape that creates.

31:44.240 --> 31:46.240
 At each point, at each pixel, right?

31:46.240 --> 31:51.720
 Yeah, so we have like the five pixels that we've made white and we kind of

31:51.720 --> 31:56.320
 like are putting Gaussians centered at each of those and looking at the

31:56.320 --> 32:03.480
 distribution that creates. Let me pull up the documentation though.

32:03.480 --> 32:12.760
 Oh, there it goes.

32:17.240 --> 32:23.720
 Yeah, I guess it is like Jeremy saying that he thinks it's like a convolution.

32:23.720 --> 32:31.080
 Yeah, I think that's accurate.

32:31.080 --> 32:56.240
 Like what this, um, I'm just going to grab my stylus. What this looks like in 1D,

32:56.240 --> 33:10.040
 I guess kind of in 1D, would be like taking the points you have and if

33:10.040 --> 33:31.440
 you put like a Gaussian around each of those and then you're kind of looking at a, looking at the method that covers all of these, you kind of hear

33:31.440 --> 33:34.720
 about this in kernel methods sometimes, kind of like looking at where your data

33:34.720 --> 33:41.640
 is and then kind of using Gaussians to construct a distribution kind of based

33:41.640 --> 33:47.360
 around that data. Yeah, good question.

33:47.360 --> 33:57.960
 Any other questions?

33:57.960 --> 34:22.200
 Matthew, on the Gaussian? Yeah. So what that's doing, yeah, so I think Jeremy

34:22.200 --> 34:25.800
 yeah, pointing out it's a convolution is helpful. It's kind of like blurring the

34:25.800 --> 34:30.320
 points around wherever we had these white pixels. So we were kind of starting

34:30.320 --> 34:33.940
 with this picture and so you could think of that as kind of doing this averaging

34:33.940 --> 34:38.160
 method to kind of even out the squares around this and so that's why we kind of

34:38.160 --> 34:42.000
 have it very white in the corner, but you know if we take a point here and get the

34:42.000 --> 34:46.960
 average of the stuff around it, you know that's gonna be gray whereas a point

34:46.960 --> 34:51.100
 here an average of everything around it's still gonna be black and that's a

34:51.100 --> 34:57.360
 way that kind of like smooths it out. Hi, you're welcome.

35:02.840 --> 35:11.960
 Okay. And we can always come back to this later too. So this is, yeah, so that's kind

35:11.960 --> 35:18.040
 of just to getting that kind of picture with the globs that in the end

35:18.040 --> 35:22.560
 it's gonna be what we're trying to recreate. The next step is to generate

35:22.560 --> 35:27.760
 the projections and so this will be the kind of the single value that we get

35:27.760 --> 35:36.320
 from shooting an x-ray at a particular angle through our picture. So

35:36.320 --> 35:39.720
 again I'm gonna walk walk through this and this is something where you don't

35:39.720 --> 35:50.160
 have to understand every line of the code. But more I want you to kind of get

35:50.160 --> 35:54.680
 the idea of like what the steps are. I should also just while it's on the

35:54.680 --> 36:00.960
 screen want to highlight and here we're using sparse dot COO matrix in this line

36:00.960 --> 36:11.520
 for our operator. Yeah, so here we're kind of feeding in what the dimensions we

36:11.520 --> 36:16.320
 want it to be and we have L as well as L divided by 7 and again the idea is

36:16.320 --> 36:23.480
 that we're using less radiation than kind of you know taking it at every

36:23.480 --> 36:35.640
 single angle and every single location. And so this creates, we'll kind of come

36:35.640 --> 36:41.720
 back to what this what this matrix looks like, but we've got a sparse matrix in

36:41.720 --> 36:46.580
 coordinate format and then there is a dense method which converts

36:46.580 --> 36:51.760
 sparse matrices to dense and it's very useful and that'll be helpful when we're

36:51.760 --> 36:56.880
 wanting to plot what we're doing. We need to have it dense for for creating these

36:56.880 --> 37:05.040
 images. But the idea is that the so the first the first dimension is going to

37:05.040 --> 37:10.320
 tell you the angle and we only have L over 7 angles and then we have L

37:10.320 --> 37:18.880
 positions. So that's kind of every single pixel height and then each image is L by

37:18.880 --> 37:27.880
 L. So we're gonna be getting something that's L over 7 by L by L by L. So just

37:27.880 --> 37:36.000
 to kind of get a feel for this matrix, this is an angle indexed with three

37:36.000 --> 37:43.480
 and we're kind of have it starting from zero or just kind of position zero and

37:43.480 --> 37:47.000
 then you'll notice the positions moving and basically getting lower each time. So

37:47.000 --> 37:51.080
 then this is position one which is really from this distance almost looks

37:51.080 --> 37:58.280
 identical, but the line is slightly lower than the previous picture. You can go on

37:58.280 --> 38:06.160
 two and it becomes more obvious if you say go to position 40. So now we can see

38:06.160 --> 38:12.280
 that okay we've definitely been lowering this angle, kind of keeping same angle in

38:12.280 --> 38:16.040
 this case the angle with index three and going to a different position. So now

38:16.040 --> 38:22.720
 we're lower kind of down to 40 and then we can look at other other angles at

38:22.720 --> 38:27.320
 vertical location 40. So now I'm changing the first coordinate to be a 5 and this

38:27.320 --> 38:35.600
 is a different angle. Actually let me kind of show like if you did 4 comma 40

38:35.600 --> 38:45.600
 that's giving you something in between angles 3 and angle 5. And so what we have

38:45.600 --> 38:51.280
 is a kind of a matrix that's keeping track of all these different angles and

38:51.280 --> 39:02.200
 locations. Here we can see this is a completely different angle the one

39:02.200 --> 39:10.680
 indexed with number 15 and at location 40 still. This is angle index with

39:10.680 --> 39:15.680
 17 at location 40. So we're kind of getting all these different angles at

39:15.680 --> 39:21.760
 every possible location. Where here the location basically corresponds to the

39:21.760 --> 39:31.760
 height within the picture. Questions questions about this? This is a little

39:31.760 --> 39:38.800
 bit tricky because projection T is it's a matrix in four dimensions which can be

39:38.800 --> 39:43.240
 hard to think about. So here we're kind of just looking at these two-dimensional

39:43.240 --> 39:47.720
 pictures from it by indexing the first and second dimensions and then we're

39:47.720 --> 39:52.080
 seeing everything that's in the third and fourth dimension.

39:52.080 --> 40:04.080
 Matthew?

40:06.080 --> 40:12.840
 So the projection and we'll kind of get to that in a moment. The

40:12.840 --> 40:19.640
 projection is gonna talk about how we're projecting into one dimension which is

40:19.640 --> 40:25.600
 weird to think about but it's gonna be kind of taking this you know this just

40:25.600 --> 40:29.760
 line at a certain place together with our whole image and just getting a

40:29.760 --> 40:39.760
 single number from that. Yes, so oh and so that's that's representing what the CT

40:39.760 --> 40:46.920
 scan gets because the CT scan you know you've got this well the cross-section

40:46.920 --> 40:50.760
 you know two-dimensional cross-section of a person and you're sending an x-ray

40:50.760 --> 40:54.200
 at a particular angle and even though those could be represented as you know

40:54.200 --> 40:58.000
 like a 2d picture of the x-ray and the 2d picture of the cross-section of the

40:58.000 --> 41:02.360
 person you just get a single number from that which is like the reading that the

41:02.360 --> 41:07.640
 you know the CT scan or MRI machine is picking up. So kind of getting that down

41:07.640 --> 41:14.320
 to a single number. Yeah so typically so projections are kind of take something

41:14.320 --> 41:18.080
 you know that goes from a higher dimension to a lower dimension and I

41:18.080 --> 41:22.640
 think this is somewhat unusual because I feel like people often don't talk about

41:22.640 --> 41:30.480
 projections into 1d. Any other questions?

41:30.480 --> 41:44.480
 Okay so yeah now I'm just kind of showing kind of you can

41:48.920 --> 41:53.760
 transpose you know x-ray kind of going through these points we're just gonna

41:53.760 --> 42:01.200
 get a single single number from that. Oh here I've also showed just how much

42:01.200 --> 42:08.340
 intersection there is but any idea here is that the the x-ray kind of going

42:08.340 --> 42:11.960
 through different materials of different densities that's gonna affect the

42:11.960 --> 42:19.840
 reading at the end so it's got a sense of kind of what what yeah kind of like

42:19.840 --> 42:23.680
 the density of what it's passed through based on kind of what the the measurement

42:23.680 --> 42:32.000
 is. And so here I wanted to illustrate that and so we get this from so here

42:32.000 --> 42:37.400
 Proj stores the projection this is at the very beginning when I showed that

42:37.400 --> 42:46.720
 little L by 7 L over 7 by L matrix this is that the readings and so here where

42:46.720 --> 42:51.680
 there was a lot of intersection like this this x-ray was having to pass

42:51.680 --> 42:57.920
 through a lot of the a lot of the glob globules and we get a kind of larger

42:57.920 --> 43:05.920
 number 6.4 and then here you know we have a line kind of going off off

43:05.920 --> 43:09.760
 through this side part it's not really passing through much and we'll get a

43:09.760 --> 43:19.680
 lower number. Yeah just 2.1 so this is kind of how we're capturing information

43:19.680 --> 43:29.400
 of how much the line has passed through. And then we're also adding we add some

43:29.400 --> 43:34.840
 noise to that so kind of assuming that this would would involve some noise in

43:34.840 --> 43:41.080
 our measurements and then this is this is what we're referring to is kind of

43:41.080 --> 43:46.720
 the projection this this matrix but that's just all the measurements so it's

43:46.720 --> 43:53.440
 a bunch of 1D projections coming from these lines at different angles. Tim?

43:55.680 --> 44:11.000
 What's the star project shape inside that argument? That's a good question. So star in Python is used to unpack list so there's

44:11.000 --> 44:15.960
 something called star args and star star and actually let me pull this up because

44:15.960 --> 44:21.520
 this is a really useful Python concept but it's useful when you want to be able

44:21.520 --> 44:25.440
 to pass yeah like a list or dictionary of argument so the dictionary you use two

44:25.440 --> 44:27.800
 stars.

44:27.800 --> 44:46.800
 Is that a Python 3 thing? No that's in Python 2 as well, yeah. Let's see.

44:47.520 --> 44:51.280
 Yeah and this this can be useful if you kind of like have a bunch of parameters

44:51.280 --> 45:15.280
 and don't know how many you'll have. I actually find this really weird and annoying because like in some things in parts of NumPy they expect a shape as a tuple and sometimes they expect the dimensions as arguments. So in this case the thing that Rachel is using is the dimensions as arguments so you have to put the star there.

45:15.280 --> 45:26.520
 So that's true about this issue with shape but I do want to say star args shows

45:26.520 --> 45:36.400
 up other places that could be useful. Yeah actually let me show an application I

45:36.400 --> 45:47.640
 really like of star. Okay yeah I'm gonna be careful about that.

46:09.680 --> 46:26.480
 And are you are you all familiar with zip? Zip, yes. Wait that's not. I didn't know

46:26.480 --> 46:38.360
 that. Put list at the front. Okay so what zip does is you can pass it to list or

46:38.360 --> 46:42.720
 tuples and it'll of the same length and it will go through and kind of pair them

46:42.720 --> 46:47.880
 together. So here we're picking off you know one and four, two and five, three and

46:47.880 --> 47:02.400
 six. But something that's kind of fun is that I'll call this C. You can undo zip

47:02.400 --> 47:18.680
 then by using zip again together with star. So in this case we wanted to pass

47:18.680 --> 47:25.140
 to zip three things one, four, two, five, three, six, and we can do that by

47:25.140 --> 47:30.560
 unpacking this list into kind of the the three tuples using star. So that's a way

47:30.560 --> 47:34.960
 that lets you get your your original two back.

47:40.840 --> 47:44.400
 Okay other questions about this figure? And that was yeah a great question about

47:44.400 --> 47:49.920
 star args. Matthew?

47:49.920 --> 47:58.400
 So you have the value that you're getting back. You're reading your highlighting in the matrix.

47:58.400 --> 48:08.560
 Say that again, the values that you're reading. Yes, yes, yeah. And then what are the x and y axis again?

48:08.560 --> 48:15.320
 For this matrix the, great question, the x-axes are the different angles and then

48:15.320 --> 48:20.960
 the y-axes corresponds to the different kind of vertical position. So when we

48:20.960 --> 48:24.520
 showed how like you know there's a line here and then lower yeah that's what the

48:24.520 --> 48:30.280
 the y-axis is corresponding to here. Thank you. You're welcome.

48:40.400 --> 48:44.920
 Alright so now that, so here the hard part was creating this data set and it's

48:44.920 --> 48:53.320
 actually going to be pretty quick to get back to our answer. We're going to use

48:53.320 --> 49:01.160
 use regression to try to recover the data. We'll start out with the L2

49:01.160 --> 49:09.560
 penalization. This is called a ridge regression. And so here we're just using

49:09.560 --> 49:20.880
 scikit-learns, linear model ridge, fitting it to our projection operator and

49:20.880 --> 49:31.400
 projection. And this is this is what we get which is not not very good. And so

49:31.400 --> 49:38.520
 this was using least squares error. Now if we use L1 error which is called a

49:38.520 --> 49:47.800
 lasso regression, this is what we get which is really close to our original

49:47.800 --> 49:54.720
 picture. So this is a case where we had you know very kind of like perfectly

49:54.720 --> 50:00.680
 sparse data set and so L2 regression did really poorly and L1 regression did a

50:00.680 --> 50:14.320
 lot better. There are questions about this? Tim? Oh okay, Tim and then Terrence can go

50:14.320 --> 50:41.560
 next. Okay, okay let me think about that one. Let's hear Terrence's question.

51:10.640 --> 51:13.760
 Where are you getting polynomials from?

51:13.760 --> 51:36.480
 Well, I use polynomial but it could be a line. Yeah, yeah. We're basically adding what we see. Each pixel is the summation of what is visible from a bunch of different angles. Yes, yeah that's a good way of

51:36.480 --> 51:42.280
 putting it. Yeah, so yeah each pixel yeah it's gonna be a sum of what was seen

51:42.280 --> 51:45.200
 from a bunch of different angles.

51:45.200 --> 52:01.200
 So you're combining the lines, if you will, from these x-rays and at a particular point you know how much is there based upon the angle and the height of the electron at that time.

52:01.200 --> 52:09.200
 I think that's basically what Tim's question was that you just answered.

52:09.200 --> 52:20.280
 What? Oh okay, Jeremy's voting for a break. I just yeah, well let me say one more

52:20.280 --> 52:24.760
 thing but then yeah then we'll take a break and come back to this. Actually

52:24.760 --> 52:28.320
 yeah let's take a break and we will discuss this in more detail. So let's be

52:28.320 --> 52:40.320
 back in seven minutes so that would be 12.05. I'm gonna start back up. Yeah so let's

52:40.320 --> 52:46.600
 talk about what's going on with this regression. So just kind of to restate

52:46.600 --> 52:53.320
 the problem. So when you have a CT scan and you get the kind of like the picture

52:53.320 --> 52:58.040
 that looks like the insides, actually there's one up here, you know it looks

52:58.040 --> 53:02.000
 like a picture of organs or tumors. That's not actually what the CT scans

53:02.000 --> 53:06.160
 producing directly but rather you know it's taking these measurements and then

53:06.160 --> 53:09.520
 you know this field of compressed sensing is around how do you get from

53:09.520 --> 53:14.840
 those measurements back to or not back to but you know create a reconstruction

53:14.840 --> 53:22.480
 of what the kind of the person's organs look like. So here, so Tim asked a

53:22.480 --> 53:26.800
 great question about what's going on with this regression. So we have

53:26.800 --> 53:31.360
 something called the projection operator and that's basically kind of

53:31.360 --> 53:35.840
 like if you think of linear regression being AX equals B and you're trying to

53:35.840 --> 53:44.960
 find X. In that case, so the projection operator is A. The original

53:44.960 --> 53:53.960
 picture, which is this, is like our X and then B is the measurements we got, go

53:53.960 --> 53:59.440
 back up here, this. And it's hard to think about the projection operator

53:59.440 --> 54:04.040
 because it's a four-dimensional matrix or four-dimensional tensor and so that's

54:04.040 --> 54:16.800
 what we were trying to kind of get at up here with all these plots of Proj T. So

54:16.800 --> 54:22.200
 this is just basically kind of like a part of A. So A is this four-dimensional

54:22.200 --> 54:29.520
 matrix and we can look at slices of it but A represents the lines coming from

54:29.520 --> 54:34.440
 different angles at different locations. So it's kind of like all all the angles

54:34.440 --> 54:41.160
 and locations that the CT scans taking and it like what those look like in 2D.

54:41.160 --> 55:00.120
 So let me also, actually I think I can show that down here. So Proj operator dot

55:00.120 --> 55:06.240
 shape. Oh and that is also, it's been distorted. So this kind of was the

55:06.240 --> 55:10.840
 four-dimensional thing. We reshaped it so it was easier to look at but it's, this

55:10.840 --> 55:20.200
 is coming from having 128 over 7 which is 18, something that was 18 by 128 by

55:20.200 --> 55:26.920
 128 by 128 and we've reshaped it here just to make it two-dimensional. But the

55:26.920 --> 55:32.360
 the idea was four-dimensional that we kind of had angles by vertical location

55:32.360 --> 55:38.720
 of where the x-ray was shooting then by x-coordinate by y-coordinate of the

55:38.720 --> 55:48.360
 cross-section. So that's our matrix A and then X which we're trying to solve is

55:48.360 --> 55:54.240
 this 128 by 128 image and so we're kind of thinking about like okay we put all

55:54.240 --> 55:59.640
 these x-rays from different angles are kind of effectively being multiplied by

55:59.640 --> 56:03.560
 this image and then we get out you know the smaller matrix of measurements and

56:03.560 --> 56:06.600
 so we're trying to go backwards. Okay we've got the smaller matrix of

56:06.600 --> 56:12.800
 measurements, we've got all the x-ray angles, how can we get the the picture of

56:12.800 --> 56:18.280
 what what those x-rays were passing through.

56:22.000 --> 56:26.000
 There are more questions about this.

56:26.000 --> 56:44.120
 And I should say that here yeah like with the CT scan it kind of makes more

56:44.120 --> 56:49.180
 sense to think about okay what is what is this x-ray passing through. What

56:49.180 --> 56:52.700
 we're doing though with the fact that it's multiplying is just kind of taking

56:52.700 --> 56:58.600
 advantage of the fact that we have a lot of zeros and ones and basically every

56:58.600 --> 57:05.960
 place where either the person's organ is zero you know we've got a black spot or

57:05.960 --> 57:10.560
 where the x-ray is not passing those are all zero and so those will zero out and

57:10.560 --> 57:15.800
 so the only thing that gets picked up is where both of them are nonzero and those

57:15.800 --> 57:21.320
 are the intersections. So you can kind of see this is a different one where

57:21.320 --> 57:25.760
 they're intersecting. So if we were kind of multiplying the picture of the organs

57:25.760 --> 57:30.280
 times the picture of the x-ray that's just gonna pick up the intersections

57:30.280 --> 57:34.320
 because everything else zeros out and gives us kind of a measurement of how

57:34.320 --> 57:54.280
 many and how many locations were both of those nonzero. I have a question. So I'm

57:54.280 --> 58:06.840
 using down here prog dot ravel. Does anyone know what dot ravel does? Is that a

58:06.840 --> 58:20.720
 hand? Sam? Exactly yes. Yeah and I actually feel like unravel would make more sense

58:20.720 --> 58:25.800
 but it's yeah kind of flattening it into a one-dimensional array and that's handy

58:25.800 --> 58:34.840
 here because we're basically converting what would be a four dimensional

58:34.840 --> 58:40.000
 matrix times a two-dimensional matrix equals a two-dimensional matrix. This

58:40.000 --> 58:44.800
 kind of how I think the problem makes sense of thinking with like the CT scans

58:44.800 --> 58:50.520
 but we've converted that into a you know just typical matrix by a vector equals a

58:50.520 --> 58:57.000
 vector. And so that's why we're having to unravel these readings just to be a you

58:57.000 --> 59:00.640
 know one-dimensional array.

59:00.640 --> 59:21.280
 A lot of people look very puzzled so I'd love to get more questions. Sam? Yes yeah

59:21.280 --> 59:29.920
 so the four dimensions and let me go back up. The four dimensions are coming

59:29.920 --> 59:38.000
 from our projection operator and so those are the angle that it's at and we

59:38.000 --> 59:47.400
 have a total of L over 7 angles which in this case is 18 angles is 18 in this

59:47.400 --> 59:52.240
 case yeah so we've got 18 distinct angles L positions and that return so

59:52.240 --> 59:58.520
 this is an L by L matrix and that's just kind of each vertical possible height is

59:58.520 --> 1:00:06.600
 the position and then the image for each is L by L and so what we're displaying

1:00:06.600 --> 1:00:10.880
 here is we're kind of indexing on those first two we're picking an angle on a

1:00:10.880 --> 1:00:16.280
 position and then showing the image and so this is our way of trying to look at

1:00:16.280 --> 1:00:21.160
 little pieces of this four-dimensional array is we're just kind of you know

1:00:21.160 --> 1:00:37.840
 indexing on the first two and then viewing a 2d picture. So really we're

1:00:37.840 --> 1:00:45.600
 multiplying the last two dimensions by, we're multiplying the line in the last two

1:00:45.600 --> 1:00:52.160
 dimensions by X and that's giving us a single value that's like how much it's intersecting.

1:00:52.160 --> 1:01:05.800
 Yes. But we have first two dimensions simply because we have so many different lines at different angles and the index corresponds to which of those. Exactly.

1:01:05.800 --> 1:01:34.720
 So that again have three dimensions with the yes.

1:01:34.720 --> 1:01:51.520
 Yeah yeah yes that makes sense yeah yeah so another yeah that's a great way of

1:01:51.520 --> 1:01:57.040
 thinking about it. Another like what's happening here with the dimensions is

1:01:57.040 --> 1:02:03.880
 we're actually kind of reshaping this four-dimensional thing go down to where

1:02:03.880 --> 1:02:19.880
 I have it. So the projection operator kind of was just write it 128 by oh no

1:02:19.880 --> 1:02:38.200
 this one's 18. 18 by 128 by 128 by 128. But 18 times 128 is 2304 and 128 by 128

1:02:38.200 --> 1:02:48.440
 is 16,384. And so what's that what this is doing is you can kind of

1:02:48.440 --> 1:02:54.500
 think of you know we've turned our picture with the cellular globs or

1:02:54.500 --> 1:02:58.400
 organs or however we want to think about those. That was two-dimensional. We've

1:02:58.400 --> 1:03:03.120
 kind of unraveled that into like a single vector and then we're gonna

1:03:03.120 --> 1:03:09.160
 multiply that two thousand and three hundred two thousand three hundred and

1:03:09.160 --> 1:03:15.520
 four times. Basically like that's getting multiplied with this x-ray for we have

1:03:15.520 --> 1:03:18.920
 two thousand three hundred and four different x-rays you could think of it

1:03:18.920 --> 1:03:26.120
 since we wanted to take an x-ray reading from 18 different angles at 128

1:03:26.120 --> 1:03:29.760
 positions for each angle. So that might be helpful to kind of think of you have

1:03:29.760 --> 1:03:37.320
 2300 kind of separate yeah separate readings.

1:03:37.320 --> 1:03:55.120
 The this one yeah so this one is actually let me write it out. This is 18

1:03:55.120 --> 1:04:03.920
 by 128 but we have unraveled this into just one thing that's 2304 long. So kind

1:04:03.920 --> 1:04:08.120
 of for each of those 2304 multiplications we're doing we're getting

1:04:08.120 --> 1:04:15.400
 back one pixel here or one spot in this matrix. So this this is the result of

1:04:15.400 --> 1:04:28.560
 doing 2304 multiplications. Yes yeah so this is what the the CT scanner is

1:04:28.560 --> 1:04:34.540
 actually measuring. But then it knows the angles and locations that it's shot the

1:04:34.540 --> 1:04:48.160
 x-ray to get each of these points. Yes yes good questions.

1:04:48.160 --> 1:05:04.560
 Are there questions about this? Matthew?

1:05:08.080 --> 1:05:14.480
 So this is B in the regression. You can think of this is like the column on

1:05:14.480 --> 1:05:27.280
 the right-hand side and then A is... I need to fold some of these up. A is the

1:05:27.280 --> 1:05:50.320
 collection of all these matrices. Yes yeah yeah so it's um like I think it yeah

1:05:50.320 --> 1:05:58.120
 by the time we do the regression it is 2d. Yes yeah yeah yeah I guess actually

1:05:58.120 --> 1:06:04.740
 yeah so here we've just reshaped it as 4d to get the kind of meaning for the

1:06:04.740 --> 1:06:07.440
 different points.

1:06:11.400 --> 1:06:17.800
 And in its 2d form this picture would be like a single row. So we've kind of taken

1:06:17.800 --> 1:06:24.520
 this whole picture and made this this is one row and this picture is another row

1:06:24.520 --> 1:06:29.820
 and so on. Because we've just kind of like unraveled that picture and so each

1:06:29.820 --> 1:06:35.240
 row is a single angle and single location but then all the XY coordinates

1:06:35.240 --> 1:06:44.640
 for that angle. Well there are 18 angles but there are 128 locations. Yeah so

1:06:44.640 --> 1:06:49.720
 they're 2,000 rows.

1:06:54.440 --> 1:06:59.280
 All right so um yeah so these I should say these pictures here these are all

1:06:59.280 --> 1:07:17.000
 part of the matrix A. The picture at the bottom that's the vector B. So this is

1:07:17.000 --> 1:07:36.440
 this is the vector B when it's unraveled. No it's more like each each each single

1:07:36.440 --> 1:07:45.760
 location in this like each pixel here is a reading from one of those like entire

1:07:45.760 --> 1:07:50.920
 pictures above. So kind of taking the angle at a particular location that just

1:07:50.920 --> 1:07:58.440
 gives you a single value. So that would just be one entry here. Oh you're welcome.

1:07:58.440 --> 1:08:23.360
 Oh. Matthew? Oh. Let me think about that.

1:08:23.360 --> 1:08:33.520
 Are you thinking that the what would be the kind of the background you're trying

1:08:33.520 --> 1:08:57.120
 to remove? Yeah I mean the tough thing is you don't actually have like you don't

1:08:57.120 --> 1:09:03.160
 have the picture of the line going through the through the globs it's you

1:09:03.160 --> 1:09:11.600
 just have like a single number for each of those. Yeah yeah so that's kind of a

1:09:11.600 --> 1:09:16.200
 yeah like the point you're trying to get to is the yeah the picture of the globs.

1:09:16.200 --> 1:09:19.200
 Yeah.

1:09:19.200 --> 1:09:35.640
 Any other questions? Okay we'll probably review this at the beginning of next

1:09:35.640 --> 1:09:39.040
 class. So definitely continue to think about it. Email me if you think of kind

1:09:39.040 --> 1:09:45.440
 of other other questions because it is it's just I think a very different way

1:09:45.440 --> 1:09:49.640
 of thinking kind of like understanding what all the pieces are here. But it's a

1:09:49.640 --> 1:09:58.840
 really interesting application of regression. Alright so let's start on

1:09:58.840 --> 1:10:24.240
 these. Oh wait another question. Yes yeah so this kind of even 18 angles is

1:10:24.240 --> 1:10:30.600
 enough to get yeah like a really great reconstruction. Yeah where it's kind of

1:10:30.600 --> 1:10:36.640
 like a naive guess might be like oh maybe I need 128 angles in order to you

1:10:36.640 --> 1:10:40.160
 know be capturing data of the same dimensionality of what I'm trying to

1:10:40.160 --> 1:10:46.280
 recreate. Yeah and there's it there's an entire field that kind of focuses on

1:10:46.280 --> 1:10:51.920
 this called compressed sensing or compressive sensing. This is a topic

1:10:51.920 --> 1:10:55.760
 David Umansky knows a lot about.

1:10:59.680 --> 1:11:03.200
 Yes yeah.

1:11:13.800 --> 1:11:20.120
 Alright so the next next lesson continuing with the theme of linear

1:11:20.120 --> 1:11:27.120
 regression. We'll be looking we'll be using polynomial features but so

1:11:27.120 --> 1:11:31.240
 different linear regression problem. We're going to use a data set from

1:11:31.240 --> 1:11:38.160
 patients with diabetes. This is kind of a classic data set from a famous paper and

1:11:38.160 --> 1:11:42.240
 it's included in scikit-learn which is nice. I think I mentioned in an earlier

1:11:42.240 --> 1:11:52.880
 lesson but let me pull this up again that scikit-learn has a number of data

1:11:52.880 --> 1:11:59.680
 sets that that come with it both kind of where the data is already kind of

1:11:59.680 --> 1:12:04.040
 present with scikit-learn or where they give you data kind of loading utilities

1:12:04.040 --> 1:12:10.960
 that you can pull extra data in. So I think that's a nice nice feature. So

1:12:10.960 --> 1:12:15.920
 we'll be using this data diabetes data set so we just call load diabetes to get

1:12:15.920 --> 1:12:19.600
 the data and then we know what the feature names are just from looking at

1:12:19.600 --> 1:12:24.960
 the documentation. And so this data is going to have age, sex, BMI, blood pressure,

1:12:24.960 --> 1:12:29.760
 and then various blood serum levels.

1:12:30.960 --> 1:12:37.240
 We're going to use a trained test split which is kind of scikit-learn gives you

1:12:37.240 --> 1:12:41.560
 one there. And in here you're probably familiar, actually I'll ask you, can

1:12:41.560 --> 1:12:46.200
 someone explain why splitting into a training and test set is important in

1:12:46.200 --> 1:12:48.840
 machine learning?

1:12:50.640 --> 1:12:53.640
 Kelsey?

1:13:01.640 --> 1:13:06.400
 Exactly. You don't want to overfit to your particular data set. You're

1:13:06.400 --> 1:13:09.560
 trying to come with a model that will be general enough to handle new data and so

1:13:09.560 --> 1:13:13.920
 you want to hold out some of your data as a test set and not look at it

1:13:13.920 --> 1:13:20.680
 until the end. So we're gonna hold out 20% of our data for the test set and

1:13:20.680 --> 1:13:31.720
 that'll allow us to evaluate how well our model does on new data. So the

1:13:31.720 --> 1:13:38.480
 problem of linear regression is AX equals B and typically A has more rows

1:13:38.480 --> 1:13:42.680
 than columns. So this would be when you have more data samples than variables.

1:13:42.680 --> 1:13:51.800
 And yeah, we're trying to find an X that minimizes the L2 error which is the sum

1:13:51.800 --> 1:14:02.680
 of the squares of AX minus B. And so this is a kind of assuming that our data that

1:14:02.680 --> 1:14:07.960
 there's this linear relationship between the things we're measuring and what

1:14:07.960 --> 1:14:12.040
 we're trying to predict. And so in this case that would be a linear relationship

1:14:12.040 --> 1:14:20.080
 between age, sex, BMI, different blood serum levels, and the kind of long-term

1:14:20.080 --> 1:14:28.800
 health outcome of the patient. So we can use, and we're using linear model from

1:14:28.800 --> 1:14:37.080
 Scikit-Learn has linear regression for us. So we kind of create a

1:14:37.080 --> 1:14:42.960
 regression, fit it to our training set with the Y training data, and then make a

1:14:42.960 --> 1:14:51.960
 prediction on the test set. And then here written just a little helper method

1:14:51.960 --> 1:14:57.320
 regression metrics that returns the mean squared error as well as the mean

1:14:57.320 --> 1:15:01.520
 absolute error kind of between the actual data and between the prediction.

1:15:01.520 --> 1:15:08.680
 And so we run that and we get 75 for the mean squared error and 60 for mean

1:15:08.680 --> 1:15:15.960
 absolute error. Your questions kind of on the setup or on this is kind of a kind

1:15:15.960 --> 1:15:21.160
 of a basic linear regression so far.

1:15:28.000 --> 1:15:33.360
 All right, so now we want to try to improve this. One way we can do that is

1:15:33.360 --> 1:15:38.080
 by adding more features. And so we're going to try adding polynomial features.

1:15:38.080 --> 1:15:46.320
 And the idea here is that instead of just having it, you know, our outcome

1:15:46.320 --> 1:15:51.240
 depend linearly on these variables, we can also look at things like age squared

1:15:51.240 --> 1:15:57.200
 or age times sex, age times BMI, and so those are the interactions between the

1:15:57.200 --> 1:16:01.480
 different terms. And this is kind of letting us look for more complex

1:16:01.480 --> 1:16:08.760
 relationships. And so we're just kind of going up to the the squared version, but

1:16:08.760 --> 1:16:12.160
 so that gets how each term interacts with each other term as well as their

1:16:12.160 --> 1:16:22.120
 squared versions. And so now, and actually I should have probably put the

1:16:22.120 --> 1:16:38.320
 dimensions before we start this. So we were starting with 353 rows, so that's

1:16:38.320 --> 1:16:45.040
 probably 353 different patients, and 10 variables. If we add these polynomial

1:16:45.040 --> 1:16:53.360
 features, now we've got 65 different variables that we're looking at. And so

1:16:53.360 --> 1:17:00.680
 do a linear regression again. And we've just added, we kind of created these

1:17:00.680 --> 1:17:05.440
 training features and now using those to fit our regression, and that improves our

1:17:05.440 --> 1:17:15.480
 error. So we, before I think had 75 and 60, now we've got 55 and 42. Unfortunately

1:17:15.480 --> 1:17:21.960
 time is squared in the number of features, and so this is this is going

1:17:21.960 --> 1:17:27.600
 to slow us down a lot. And we can look, let's go back up here.

1:17:27.600 --> 1:17:41.720
 Here's the time. So before it was 535 microseconds, and I think we've seen this

1:17:41.720 --> 1:17:48.120
 before, but using percent time it in a Jupyter notebook runs, so here this is

1:17:48.120 --> 1:17:54.520
 doing seven runs, a thousand loops each, kind of runs it multiple times and then

1:17:54.520 --> 1:17:58.640
 gives you this average of how long it takes. So it's a really useful way to

1:17:58.640 --> 1:18:08.720
 compare the times of things. Okay so that was 535 microseconds, so now

1:18:08.720 --> 1:18:14.400
 we're up to 635 microseconds. So it's not that much worse in this case, but it's

1:18:14.400 --> 1:18:24.280
 something that's going to, on larger data sets, be an issue. Or was there also

1:18:24.280 --> 1:18:32.040
 look at the plus-minus. What?

1:18:55.440 --> 1:19:01.660
 Oh yes, I'm sorry. So yeah, the one above was to do the linear regression. This is

1:19:01.660 --> 1:19:16.600
 just to pull. Okay, so this is just to create the features, sorry to create

1:19:16.600 --> 1:19:21.120
 these polynomial features. Sorry about that. And so that's, you're having to take

1:19:21.120 --> 1:19:25.360
 all the data points and multiply them together, you know, all possible pairs and

1:19:25.360 --> 1:19:29.720
 doing that calculation just to even create this set of polynomial data is

1:19:29.720 --> 1:19:35.640
 taking even longer than it took just for us to do the linear regression, but we're

1:19:35.640 --> 1:19:40.520
 still gonna have to do a linear regression on this this new data set. So

1:19:40.520 --> 1:19:49.080
 this is this is kind of a time concern. So it's something that has, yeah, improved

1:19:49.080 --> 1:19:58.280
 improved our error, but it's gonna slow us down. So we're gonna look at a way to

1:19:58.280 --> 1:20:03.360
 speed up the feature generation. First I should stop. Are there any questions on

1:20:03.360 --> 1:20:08.080
 how the polynomial features allow us to kind of create a better model than the

1:20:08.080 --> 1:20:20.920
 plain linear linear regression, but then they take longer to calculate? Okay, so

1:20:20.920 --> 1:20:25.400
 we're gonna use Numba today, which is a Python library that compiles directly to

1:20:25.400 --> 1:20:34.240
 C. Jake Vander Plas has some nice tutorials on them, and I like in this

1:20:34.240 --> 1:20:42.280
 tutorial he says that a lot of people ask him isn't Python pretty slow, and

1:20:42.280 --> 1:20:45.880
 he's kind of got an answer of why he likes, and Jake Vander Plas I should say

1:20:45.880 --> 1:20:50.160
 has a PhD in astrophysics and works at the University of Washington, has like a

1:20:50.160 --> 1:20:55.400
 Center for Data Science, and he he's a contributor to a lot of Python

1:20:55.400 --> 1:21:01.480
 scientific packages and does a lot of speaking, and also I think helps run like

1:21:01.480 --> 1:21:05.200
 University of Washington's kind of like at their Data Science Institute. They

1:21:05.200 --> 1:21:09.280
 have like, you know, data science for social good, summer programs and

1:21:09.280 --> 1:21:14.860
 things, but he goes through kind of reasons why he likes having a Python

1:21:14.860 --> 1:21:18.880
 implementation as opposed to just, you know, doing the whole thing in Fortran

1:21:18.880 --> 1:21:24.480
 or C, and it's, you know, Python code is easier to read, understand, and contribute

1:21:24.480 --> 1:21:32.960
 to. Pure Python packages are easier to install than Python wrapped C or Fortran

1:21:32.960 --> 1:21:41.400
 code. It's easy to use at scale, so I think these are kind of some good

1:21:41.400 --> 1:21:46.200
 arguments for why you would want to maybe compile some of your Python code

1:21:46.200 --> 1:21:52.160
 to C as opposed to just switching to C or Fortran completely, and Numba is one

1:21:52.160 --> 1:21:55.840
 way, one way to do that.

1:22:01.600 --> 1:22:09.080
 So from here, from Numba, we're importing a number of methods and decorators

1:22:09.080 --> 1:22:13.640
 and types that I'll kind of talk about as we use them. So we're going to step

1:22:13.640 --> 1:22:19.000
 back from the problem of this linear regression or polynomial feature

1:22:19.000 --> 1:22:22.600
 generation and just talk about what Numba is and how to use it and kind of

1:22:22.600 --> 1:22:26.520
 go through a sample problem.

1:22:31.240 --> 1:22:39.360
 So Numba is going to allow us to kind of avoid memory allocations and copies and

1:22:39.360 --> 1:22:46.120
 give us better locality. So we're going to start with kind of this toy example.

1:22:46.120 --> 1:22:54.320
 So this is something just in plain Python and NumPy where we have some

1:22:54.320 --> 1:22:58.760
 number of observations that we're looping through. We've got two different

1:22:58.760 --> 1:23:05.480
 arrays, X and Y, and we kind of want to take each each value in X and Y, do some

1:23:05.480 --> 1:23:10.720
 computations on them, and then store them in array Z. So this is just a process in

1:23:10.720 --> 1:23:26.120
 Python. Notice since we're using NumPy we can give ZZ a type. This says, or I'll

1:23:26.120 --> 1:23:32.040
 ask you, do X and Y have types here?

1:23:32.040 --> 1:23:41.640
 And actually this is confusing because I named these variables X and Y. Do X and Y

1:23:41.640 --> 1:23:46.680
 inside this inner loop have types?

1:23:46.680 --> 1:24:10.840
 Does anyone want to make a guess? So Malton is suggesting float 32. So for our

1:24:10.840 --> 1:24:16.280
 arrays X and Y that we're passing in we have float 32 and ditto for ZZ where

1:24:16.280 --> 1:24:21.800
 we're going to put our result we have float 32. But here inside the loop we

1:24:21.800 --> 1:24:25.520
 have these kind of just, you know, temporary variables X and Y we're using

1:24:25.520 --> 1:24:30.840
 and those don't have specific types. So even though they're actually all, we're

1:24:30.840 --> 1:24:38.560
 always going to be putting float 32s in them, Python doesn't know that. And that's

1:24:38.560 --> 1:24:44.560
 kind of one of the things that, so Python is not a typed language but in

1:24:44.560 --> 1:24:49.920
 language type languages like C or C++ you have to say, you know, what type

1:24:49.920 --> 1:24:54.840
 of variable it is when you declare it and that, you know, lets it know

1:24:54.840 --> 1:25:00.920
 how much memory to set aside. And so it's kind of better for optimization although

1:25:00.920 --> 1:25:03.840
 some people prefer that, you know, Python is flexible and you can give it

1:25:03.840 --> 1:25:16.760
 different types and not have to declare it. So here we're timing this time to

1:25:16.760 --> 1:25:21.360
 just kind of take in our two arrays, go through each of them, do all these

1:25:21.360 --> 1:25:29.600
 operations, and create an output and that's taking 49 milliseconds. So this

1:25:29.600 --> 1:25:34.400
 was a kind of the worst version. What would be a way, before we even get to

1:25:34.400 --> 1:25:43.880
 Numba, a way to improve this? Just speed it up.

1:25:43.880 --> 1:25:55.880
 All right, Jeremy, through the microphone.

1:25:55.880 --> 1:26:05.880
 We can try to avoid the for loop. Yes. Hoping that the hardware will make it in parallel. Yes.

1:26:05.880 --> 1:26:09.920
 Yeah, so this for loop seems like a bad idea because it's like we're

1:26:09.920 --> 1:26:14.240
 individually going through, you know, each pair of elements in the arrays.

1:26:14.240 --> 1:26:21.920
 We're doing the exact same thing but NumPy lets us vectorize that. So we can

1:26:21.920 --> 1:26:26.120
 here take out the for loop all together and kind of just do the operations on

1:26:26.120 --> 1:26:33.120
 the entire matrices thanks to NumPy. And so if we compare, this was 49

1:26:33.120 --> 1:26:40.840
 milliseconds, this is 35 microseconds. So notice that's over a thousand

1:26:40.840 --> 1:26:47.320
 times better. The units have changed from milliseconds to microseconds. So

1:26:47.320 --> 1:26:50.400
 that's a big speed up. So that's some really great that NumPy lets us

1:26:50.400 --> 1:27:03.640
 vectorize. Does anyone remember the other kind of technical term or buzzword that

1:27:03.640 --> 1:27:14.360
 we often say along with vectorize? It's actually an acronym.

1:27:14.360 --> 1:27:21.320
 Yeah, SIMD. So single instruction multiple data. So that's

1:27:21.320 --> 1:27:28.280
 what NumPy is letting us do here because we are doing the same

1:27:28.280 --> 1:27:33.360
 instruction on all these different entries in X and Y.

1:27:33.360 --> 1:27:48.560
 So now Numba has something called a just-in-time compiler decorator. And in

1:27:48.560 --> 1:27:55.160
 Python decorators are kind of these methods that are applied to functions to

1:27:55.160 --> 1:28:00.120
 kind of alter how your function works that show up with an at sign above the

1:28:00.120 --> 1:28:05.400
 above the method. So this is pretty simple. So we imported JIT from Numba

1:28:05.400 --> 1:28:10.480
 above, and again JIT stands for just-in-time compiler, and we just add

1:28:10.480 --> 1:28:19.360
 add JIT on top here, apply it to, so we've got our for loop back so this is kind of

1:28:19.360 --> 1:28:29.720
 or this is the the code from the top original Python process. And what this

1:28:29.720 --> 1:28:36.160
 does is so we're no longer vectorizing but we do have better better locality

1:28:36.160 --> 1:28:45.560
 here. And now when we run it we're down to six microseconds. So the version with

1:28:45.560 --> 1:28:53.360
 NumPy was almost 36 microseconds. So this is six times quicker. And then the

1:28:53.360 --> 1:29:00.400
 one in plain Python with the for loop was really slow. That was like 50

1:29:00.400 --> 1:29:03.080
 milliseconds.

1:29:11.160 --> 1:29:21.320
 Does anyone want to say what does it mean to have better better locality? Kind of

1:29:21.320 --> 1:29:24.960
 learned about this with Brad?

1:29:33.320 --> 1:29:38.720
 Yes, yeah so it's well it's um you're kind of you're accessing data that's

1:29:38.720 --> 1:29:49.200
 close to each other in memory. Yeah I mean so it's often I mean you can talk

1:29:49.200 --> 1:29:54.040
 about time locality or space locality but it's kind of using things that you

1:29:54.040 --> 1:30:00.960
 access kind of like when you access or when you access something use it

1:30:00.960 --> 1:30:04.640
 multiple times before you write it back to slow memory. So kind of like while you

1:30:04.640 --> 1:30:08.840
 have it in fast memory like do all the operations you need with it as opposed

1:30:08.840 --> 1:30:14.140
 to writing something you know or carrying something from slow memory to

1:30:14.140 --> 1:30:18.160
 fast using it taking it back to slow bringing it to fast again using it again

1:30:18.160 --> 1:30:22.120
 trying to consolidate all those uses and then yeah I'm using things next to each

1:30:22.120 --> 1:30:26.560
 other. Great, thank you.

1:30:32.400 --> 1:30:38.120
 And so here I think it can seem to be kind of counterintuitive that we've put

1:30:38.120 --> 1:30:45.520
 the for loop back in but the idea is that we're kind of you know we're

1:30:45.520 --> 1:30:50.440
 picking up X and Y which we need and then we do a bunch of operations with X

1:30:50.440 --> 1:30:55.320
 and Y and this is you know this is kind of a toy toy example but you could have

1:30:55.320 --> 1:30:58.640
 a more complicated algorithm where you are you know using them multiple times.

1:30:58.640 --> 1:31:03.620
 What would happen what would happen if we were doing this in numpy without the

1:31:03.620 --> 1:31:06.040
 for loop?

1:31:06.040 --> 1:31:19.600
 So kind of this example up here has potentially has poor locality. Why is

1:31:19.600 --> 1:31:21.800
 that?

1:31:21.800 --> 1:31:31.240
 Sam?

1:31:58.640 --> 1:32:04.440
 Yes yeah so the issue with the the numpy array is if you want to do something on

1:32:04.440 --> 1:32:09.640
 all of X maybe all of X doesn't fit in cache and so you're pulling in part of

1:32:09.640 --> 1:32:13.440
 it you know doing the operation on that part then you have to pull in the next

1:32:13.440 --> 1:32:17.040
 part of X do the operation on that part pull in another part of X do the

1:32:17.040 --> 1:32:20.560
 operation on that part and then you go on to the next line and you're like oh I

1:32:20.560 --> 1:32:25.840
 need the first part of X again and this is you know if X is a really long array.

1:32:25.840 --> 1:32:32.640
 Thank you. There questions about this?

1:32:33.720 --> 1:32:38.400
 These are kind of getting at the concepts we saw back in week one with

1:32:38.400 --> 1:32:51.160
 the highlight video. Okay so let's go on to make this even a little bit better.

1:32:51.160 --> 1:32:58.480
 Numba also has a vectorized decorator so here we're using numba instead

1:32:58.480 --> 1:33:05.960
 instead of numpy so at this one we use the just-in-time compiler decorator and

1:33:05.960 --> 1:33:11.920
 kept the for loop now we're taking out the for loop and just have the vectorized

1:33:11.920 --> 1:33:19.920
 decorator and it's actually like I mean it's almost equivalent to the using the

1:33:19.920 --> 1:33:24.760
 just-in-time compiler which was 6.4 microseconds this is 5.8 but it's kind

1:33:24.760 --> 1:33:29.200
 of good to know these two different options. Tim?

1:33:29.200 --> 1:33:38.880
 What's the difference between numba's vectorized and numpy's vectorized?

1:33:38.880 --> 1:33:46.720
 So this is still compiling to C and it's still optimizing what

1:33:46.720 --> 1:33:53.480
 happens. So it's not doing like with numpy where it's doing this like you

1:33:53.480 --> 1:33:58.340
 know having to use all of X so it's you know might pull the first part of X into

1:33:58.340 --> 1:34:01.560
 cache and then pull in the second part and then pull in the third part and then

1:34:01.560 --> 1:34:05.160
 the next line it has to use X again so it starts again with the first part of X.

1:34:05.160 --> 1:34:12.880
 Numba has optimized that away so it's not gonna yeah do that sort of thing and

1:34:12.880 --> 1:34:21.400
 the the reason numba's able to do this is because because it's compiling to C

1:34:21.400 --> 1:34:27.440
 so Python like when it's running dynamically it you know it like it

1:34:27.440 --> 1:34:30.600
 doesn't know that oh I'm gonna use X again in the next line and so this is

1:34:30.600 --> 1:34:34.720
 kind of wasteful that I'm pulling each section into cache and then putting them

1:34:34.720 --> 1:34:39.960
 back when I'm gonna have to do that again one line from now whereas C is able

1:34:39.960 --> 1:34:43.720
 to optimize things like that and so that's kind of what numba's getting you

1:34:43.720 --> 1:34:51.080
 is this kind of big picture optimization.

1:34:51.080 --> 1:34:59.040
 Numpy does use C yes that's true but that's kind of on an operation scale

1:34:59.040 --> 1:35:12.680
 whereas like yes yeah yeah whereas here even though numpy yeah is using C on an

1:35:12.680 --> 1:35:15.960
 operation scale you still kind of it doesn't have this knowledge between

1:35:15.960 --> 1:35:19.880
 lines of like hey I'm using X in this line but I'm about to use X again in

1:35:19.880 --> 1:35:38.200
 this very next line yeah I'm actually not sure about that I think they

1:35:38.200 --> 1:35:57.160
 recommend just using one but all I can look at that what Oh using but thanks

1:35:57.160 --> 1:36:12.640
 good questions okay yeah and actually I guess in the interest of time should

1:36:12.640 --> 1:36:19.240
 probably stop here so next time we'll be applying this to going back to our

1:36:19.240 --> 1:36:22.080
 problem of wanting these polynomial features but wanting to be able to

1:36:22.080 --> 1:36:27.140
 create them more quickly I also wanted to remind you that Thursday homework

1:36:27.140 --> 1:36:38.600
 two is due and so is the draft of your writing assignment Tim um so I mean the

1:36:38.600 --> 1:36:42.560
 better shape your draft is in I think the better feedback you'll get which

1:36:42.560 --> 1:36:50.200
 will make your final better but it should be it's like reasonably complete

1:36:50.200 --> 1:36:59.080
 all right any other questions all right I'll see you on Thursday

