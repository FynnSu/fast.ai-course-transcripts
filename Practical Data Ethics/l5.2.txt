 So let's get started for our kind of final, final class. I'm going to be finishing up the lesson on our ecosystem. I just briefly wanted to review what I was talking about last week and talked about Goodhart's law. When a measure becomes a target, it ceases to be a good measure. Another variation of this is Campbell's law. The more any quantitative social indicator is used for social decision-making, the more subject it will be to corruption pressures and the more apt it will be to distort and corrupt the social processes it's intended to mirror, to monitor. And so I've written about this more in a blog post and later a paper that overemphasizing metrics can lead to manipulation, gaming, myopic focus on short-term goals because it's much easier to measure short-term quantities as opposed to kind of long-term complex relationships, unexpected negative consequences, and unfortunately a lot of AI and machine learning centers on optimizing a metric. So one example I shared last week came from England's health care system which in the early 2000s implemented a number of kind of performance metrics for accountability. There were targets around shortening ER wait times and this led to hospitals canceling scheduled operations so that they could send extra staff into the ER, requiring patients to wait in lines of ambulances outside the hospital because that didn't count as part of their ER wait time, turning stretchers into beds by putting them in hallways, and discrepancies in the numbers reported by hospitals versus by patients. So if you asked hospitals how long people were waiting, you're getting very different answers than if you ask patients how long they were waiting. In the U.S. we've seen a lot of pressure around standardized testing leading to kind of widespread cheating scandals by school systems as well as kind of schools focusing so myopically on teaching to the task that they're leaving out a lot of other things. So that's just kind of a brief review about some of the issues with metrics. One of the readings from week five that we didn't get to last time was the platform is the message by James Gremelman and so I enjoyed this and he talks about how kind of with meme culture there's no example of a kind of totally kind of pure and earnest statement but also it's never kind of totally ironic or a joke either that there's kind of this in between and that he gives this example about eating that the Tide Pod challenge which kind of the earliest mention of was this Onion article from 2015 which clearly seemed to be a joke but then when this became an issue you had people kind of even in denouncing the Tide Pod challenge is very dangerous that's you know further promoting it and kind of encouraging its spread. He wrote online culture is awash in layers of irony there's a sense in which there's no such thing as a pure exemplar of eating a Tide Pod unironically or a critique of the practice that it's not also in part an advertisement for it. And then a quote I particularly like is he highlighted that the platforms are structurally at war with themselves the same characteristics that make outrageous and offensive content unacceptable are what make it go viral in the first place. I'm going to ask if there are any kind of reactions to this paper from last week. Anyone in the room? All right, another paper I liked and I think this was an optional reading was by Tom Slee, The Incompatible Incentives of Private Sector AI, and he talks about this idea of the algorithm guardrail arbitrage which is when a recommendation system is promoting content that violates its community guidelines. So there the guardrails are kind of the community guidelines of what's unacceptable or should be taken down and that often these things are in conflict that a recommendation system is promoting something that maybe technically is against the community guidelines. However, companies have a financial incentive to keep that gap wide and they can kind of arbitrage across kind of you know if they're called out pointing to their guidelines of like oh no we don't support this sort of thing yet continuing to profit in instances where they're they're not called out about it. I thought that was a kind of helpful helpful framing and again it points to this kind of a structural tension or even war of kind of the misaligned or kind of different incentives depending on your perspective. Slee also writes about how social media recommender algorithms have three qualities needed for highly elastic but also highly fragile systems. Those are that experimentation is very affordable so people can you know automatically automate generating content and just put a ton of content out there and see what's rewarded what's not. They get fast feedback in the forms of likes and views and it has a high impact on the recommendation system and these three qualities kind of all really encourage gaming and manipulation because they make it make it cheap and efficient to do so. All right let me check the the group chat to see any comments. Someone said they really like this paper, a great explanation of meme culture. Any comments from in person? All right so the the next set of things I want to talk about is to kind of understand broadly some of the forces at work in tech particularly venture capital hyper growth and blitz scaling. And so I think it's important to understand these to kind of understand the patterns of why we keep seeing companies that have some of the same ethical pitfalls. This reminds me a little bit of Zeynep Tafekci's article on sociological storytelling but understanding some of the kind of sociological forces that have led to kind of our current state. And so I've written a little bit in a different context. I wrote a blog post two years ago and I want to highlight everything I'm saying is a generality like there definitely exceptions to these but on the whole I think there are a lot of downsides to venture capital and to hyper growth and this is not to say that they're never useful or there are no cases where they're where they're helpful. I think that venture capital in many cases can push what could have been a successful kind of sustainable business to overexpand and ultimately fail and that there's often a lot of misalignment of incentives between VCs and founders and the rest of society more broadly. And so this is kind of showing up in the media more. Here's a venture capitalist saying that the vast majority of entrepreneurs should not take venture capital because it's a binary swing for the fences exercising exercise. There was a New York Times article on more entrepreneurs that are just not even interested in in venture capital. And so Tim O'Reilly talks about kind of a lot of related issues in his post that was a sign reading last week. And kind of the the premise of our kind of current system is that if a company grows big enough and fast enough that profits will eventually follow. So kind of if you can just get really big really fast like it's gonna have to work out that you're profitable is the the hypothesis. And kind of one philosophy this goes under is blitzscaling which Reid Hoffman and Chris Yeh wrote a book on. And it really prioritizes speed over efficiency and risk potentially disastrous defeat but with the idea that there's a lot of upsides if you're successful. And Tim O'Reilly is very critical of this approach in his in his article. And so first just how is how is this related to data ethics and what we're talking about. I'm having this kind of hyper growth typically requires automation and reliance on metrics. This isn't something you can kind of do just just using people or human decision makers. You typically are going to be having to use a lot of automation and data. I also think that prioritizing speed above all else doesn't leave time to reflect on ethics. And then when you do have problems they happen at a large scale. And so I think if the company is kind of growing in a more sustainable manner you know you there might be a problem but you can recognize it when the company is still small and before it's impacted too many people. If you kind of grow at a very fast scale your problem may be impacting millions of people before before it becomes a parent. Let me pause here. I'll check the group group chat. Can you explain a little bit more about why it's important to have high elasticity? I had trouble understanding of the concept. Oh sorry about that. So that's going back. There's a little bit of latency with the the YouTube stream. So let me go back to the slide on elasticity. And so actually what this was saying that is that high elasticity is a risk. So it's associated with high fragility and so kind of the fact that people can experiment so easily this is actually a bad thing just because it leads to a lot of gaming and manipulation. And so this was kind of painting it in a negative light of kind of what the risks are of kind of being so elastic because the the recommendation system is really responding quickly and content creators are responding quickly in terms of creating lots of content and getting this feedback. The system can change very quickly but these same factors are what lead to to manipulation. And so let me go back to the the chat. And so yeah let me know if that explanation was helpful in the chat and I'll move on to some of the other comments. One person said as a VC I agree with these points about venture capital. Uber, Lyft is going to be a good case study. They bootstrapped for growth without profitability. What happens now? And I think on the kind of Uber, Lyft example something that is to me kind of odd to see is I there were you know there were cities and areas where Uber and Lyft could be profitable but because they were going for this particular Uber for this kind of world domination approach they you know did end up trying to compete in a number of markets where they were just constantly losing money and that they did ultimately pull out of particularly in Asia. I know so I think there's already kind of been a cost to that. Another comment can also state that more and more AI powered startups build data products and don't think about ethical applications during the building and testing phases. Someone says I love the long-termism movement such as long now, FHI at Oxford for these kinds of reasons, kind of the opposite of moving fast and breaking things ideologically. So those are some comments from the chat. Any comments from in person? All right. So going back yeah so we've kind of so there's this relationship I think between hyper growth and automation and using data and also making it harder for people to reflect on the ethics of what they're doing. Some other characteristics of what happens are that investors end up kind of anointing winners as opposed to market forces, tends to create duopolies or monopolies. It's incredibly difficult for new entrants. There's a loss of control of the company often by founders. Companies can tend to spread themselves too thin in trying to achieve this, you know, kind of global monopoly status. And tons of companies using the strategy fail and so there's real survivorship bias in the success stories we hear and kind of an advice that you get from from VCs. Always be aware of kind of the survivorship bias if they're focusing on the few that were successful. However many many companies fail and I think that kind of taking venture capital in many cases can push what could have been a kind of successful but small sustainable company kind of to this brink of failure. One of the subject headings in O'Reilly's article was is it a business or a financial instrument and he shares this graph which I think is just remarkable of the percent of US IPOs with negative earnings per share at the time of IPO. And you can see it is above 80% currently. So it's really high number of companies going public that are losing money at the time they go public. So kind of seemingly not having achieved a profitable business. And if you look back kind of the only time it's been nearly as high was in 2000 right before the previous dot-com crash. But that kind of historically it was at much lower numbers. A quote from the article, Silicon Valley venture capitalists want entrepreneurs to pursue exponential growth even if doing so costs more money and increases the chances that the business will fail. So then there is a now I'm getting into that kind of the Zeynep Tafekci article she talks about and I think this is just kind of so prescient of her that she in 2012 was already really concerned about the growth of the kind of the data-driven campaign and the harms of that at a time when many people were thinking that big data would save politics. So data had you know played a significant role in the Obama campaign and Zeynep says she got a lot of negative feedback for her New York Times op-ed at the time expressing hesitation about this. And so she she talks about how he kind of went from data seeming you know to be this really kind of positive hopeful thing so it helped Obama get elected. It was helping people you know kind of revolt against dictators to now seeing it as having a lot of oppressive oppressive results. Digital platforms allowed communities to gather and form in new ways but they also dispersed existing communities. And then a quote that I think about a lot is power always learns and powerful tools always fall into its hands. This is a hard lesson of history but a solid one. And so that initially kind of even though many people whose voices you know hadn't been as widely heard were able to find a platform through through social media and technology which was very positive we're now seeing the powerful kind of manipulate it in some harmful ways. And this kind of rereading this article by Zeynep reminded me of our mediating consent article that we read in the first week and there Renee DiResta in the context of disinformation talked about this shift from you know their ways that the kind of the mainstream centralized media failed us such as perhaps not enough investigation around the Vietnam War and the the downsides there also with the Iraq War kind of not pointing out the kind of flimsy and false evidence. However now we're seeing the downsides of having kind of such a fractured fractured ecosystem. Are there thoughts on on this article? Any from the in-person crowd? Let me check the chat. Yeah and so the MIT Tech article by Zeynep how social media took us from Tahrir Square to Donald Trump asked how did digital technologies go from empowers empowering citizens to being used as tools of oppression and discord and to give several reasons even though dissidents can more easily circumvent censorship which is a positive. The public sphere is now too noisy and confusing to have as much of an impact. The new gatekeepers succeed by fueling mistrust and doubt. I mean there's a asymmetry there and that people trying to enact kind of positive change in the world have to you know convince people that here's this problem and it is something we can address as opposed to just getting people to feel mistrustful and doubtful is easier. Local journalism has been broken. When we encounter opposing views on social media it's like hearing them from the opposing team in a football stadium and so Zeynep says it's not it's not that we're like in bubbles where we don't hear the other side it's that when we do hear them we're kind of hearing them in this very amped up way you know where we feel kind of very charged up for our team and against the other team and it often kind of drives people even further into their existing views as opposed to kind of reaching a more common common understanding. We have weak digital security in the US and the conditions of social distrust, weak institutions, and detached elites made the United States particularly vulnerable to some of the things we're experiencing now. Okay and then I think I will this is kind of the conclusion of the ecosystem part and I will move move into week six. Any more thoughts on kind of our ecosystem? So this could be anything related to metrics, the forces on companies, the dynamics of of social media and of these platforms. And I wanted to talk about these things just to try to get that kind of broader view of this is these are the forces that kind of acting on tech companies and influencing us all.
